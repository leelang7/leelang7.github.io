---
layout: post
title:  "í•˜ì´í¼íŒŒë¼ë¯¸í„°(Hyperparameter)ë€?"
---

## ğŸ“ŒHyperparameterë€?

- ì—”ì§€ë‹ˆì–´ê°€ ì§ì ‘ ì„¤ì •í•´ ì£¼ì–´ì•¼ í•˜ëŠ” ë³€ìˆ˜ê°’
- ê°’ì„ ì–´ë–»ê²Œ ì„¤ì •í•˜ëŠëƒì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ ì‹œí‚¬ ìˆ˜ë„, ì €í•˜ì‹œí‚¬ ìˆ˜ë„ ìˆìŒ

> ## Hyperparameter Tuning ì„¸ ê°€ì§€ ìš”ì†ŒğŸ¥°
>
> 1. Objective Function : ìµœëŒ€í™”(ì ìˆ˜)í•˜ê±°ë‚˜ ìµœì†Œí™”(Loss, Cost)í•´ì•¼ í•˜ëŠ” ê°’
> 2. **Search Boundary** : **íƒìƒ‰ ë²”ìœ„** ì„¤ì •
> 3. **Step** : íƒìƒ‰ ì‹œ **ê°„ê²©**
>
> - Objective Functionì„ optimize í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë²”ìœ„ ë° ê°„ê²©ì„ ì„¤ì •

![img](https://velog.velcdn.com/images%2Fcrosstar1228%2Fpost%2F86ed2303-4861-4f30-8738-1ada436b4e32%2Fimage.png)
[Image Source: Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. Journal of Machine Learning Research 13, 281â€“305 (2012)]

## ğŸ“ŒGridSearch

![img](https://velog.velcdn.com/images%2Fcrosstar1228%2Fpost%2F53e2bdb0-f20f-42d5-80c5-85ec0e0034f5%2Fimage.png)

- ê°„ë‹¨í•˜ê³  ê´‘ë²”ìœ„í•˜ê²Œ ì‚¬ìš©ë˜ëŠ” hyperparameter íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜
- **í•´ë‹¹ ë²”ìœ„ ë° Stepì˜ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜**ë¥¼ íƒìƒ‰
- **ë²”ìœ„ë¥¼ ë„“ê²Œ ê°€ì ¸ê°ˆìˆ˜ë¡, Stepì„ ì‘ê²Œ ì„¤ì •í•  ìˆ˜ë¡** ìµœì í•´ë¥¼ ì°¾ì„ ê°€ëŠ¥ì„±ì´ ë†’ì´ì§€ì§€ë§Œ **ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼**
- ì¼ë°˜ì ìœ¼ë¡œ **ë„“ì€ ë²”ìœ„**ì™€ **í° Stepìœ¼ë¡œ ì„¤ì •**í•œ í›„ ë²”ìœ„ë¥¼ ì¢í˜€ ë‚˜ê°€ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì„ ë‹¨ì¶•

### when coding...

- pythonì—ì„œ `scikit-learn`ì˜ `GridSerachCV` ëª¨ë“ˆë¥¼ í†µí•´ êµ¬í˜„ ê°€ëŠ¥

### parameters

- *estimator* : ì¸¡ì •ì— ì´ìš©ë˜ëŠ” model
- *param_grid* : gridsearchì— ì‚¬ìš©ë˜ëŠ” search space
- *scoring* : ì„±ëŠ¥ ì¸¡ì • metric. 'accuracy', 'roc_auc', 'r2', 'neg_mean_squared_error' ë“±
  (ì´ì™¸ì˜ scoring parameterëŠ” [ì—¬ê¸°](https://scikit-learn.org/stable/modules/model_evaluation.html) ì„œ í™•ì¸
- *n_jobs* : gridsearch ì‹œ, multicore processorì¼ ê²½ìš° ë³‘ë ¬ì²˜ë¦¬í•  íšŸìˆ˜
- *cv* : cross-validation ì‹œ fold ìˆ˜

### âœ’gs = GridSearchCV(~)ì¸ìŠ¤í„´ìŠ¤ ì„ ì–¸ ì‹œ

- gs.best_params_ : ê°€ì¥ ì¢‹ì€ parameter
- gs.best_score_ : ê·¸ ì ìˆ˜
- gs.best_estimator_ : ê°€ì¥ ì¢‹ì€ ëª¨ë¸

## ğŸ“ŒRandomsearch

![img](https://velog.velcdn.com/images%2Fcrosstar1228%2Fpost%2F69edc8ad-4db8-405a-b755-ec8ef8fcfe97%2Fimage.png)

- ì •í•´ì§„ ë²”ìœ„ ë‚´ì—ì„œ Randomí•˜ê²Œ ì„ íƒ
- ê¸°ë³¸ì ìœ¼ë¡œëŠ” ë” ë¹ ë¥´ê³  íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì— GridSearchë³´ë‹¤ ê¶Œì¥ë˜ëŠ” ë°©ë²•
- **Grid Serachë³´ë‹¤ ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ** optimzed solutionì´ ì•„ë‹ ìˆ˜ ìˆìŒ
- Sampleì˜ ìˆ˜ê°€ ë§ë‹¤ë©´ Random Samplingì„ í†µí•´ ìµœì í•´ë¥¼ ì°¾ì„ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§

### when coding...

- pythonì—ì„œ `scikit-learn`ì˜ `RandomSearchCV` ëª¨ë“ˆë¥¼ í†µí•´ êµ¬í˜„ ê°€ëŠ¥

### parameters(gridsearchì™€ ê²¹ì¹˜ëŠ” paramter ìƒëµ)

- *n_iter* : randomí•˜ê²Œ ê³¨ë¼ì§€ëŠ” hyperpareter ì¡°í•©ì˜ ìˆ˜ë¥¼ íŠ¹ì •í•©ë‹ˆë‹¤. ê°’ì´ 10ì¸ ê²½ìš°, sizeê°€ 10ì¸ hyperparameter ì¡°í•©ì„ ê³ ë ¤í•©ë‹ˆë‹¤.
- *random_state* : random ë³€ìˆ˜ ìƒì„± ì‹œ seed ê°’

> ğŸ¤¡GridSearch ì™€ RandomSearch ë¥¼ êµ¬í˜„í•œ ê²°ê³¼ëŠ” [ì—¬ê¸°](https://github.com/crosstar1228/ML_optimization/blob/main/[ML]GridSearch_RandomSearch.ipynb)ë¥¼ í´ë¦­í•˜ì‹œë©´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ŒBayesian Optimization

- GridSearchì™€ RandomSearchëŠ” ê° Searchê°€ ì¢…ì†ë˜ì–´ ìˆì§€ ì•ŠìŒ(ì„œë¡œ ê°„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
- ë”°ë¼ì„œ ì°¾ì•„ë‚¸ ê°’ì´ ìµœì ì˜ ê°’ì´ë¼ê³  ìƒê°í•  ìˆ˜ ì—†ìŒ

> ### Bayesian Optimizationì€...
>
> 1. "Gausain Process"ë¼ëŠ” í†µê³„í•™ì„ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ëª¨ë¸ë¡œ,
> 2. ì—¬ëŸ¬ê°œì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë“¤ì— ëŒ€í•´ì„œ,
> 3. "Aqusition Fucntion"ì„ ì ìš©í–ˆì„ ë•Œ,
> 4. "ê°€ì¥ í° ê°’"ì´ ë‚˜ì˜¬ í™•ë¥ ì´ ë†’ì€ ì§€ì ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.

### ëª©ì í•¨ìˆ˜ì˜ 'í˜•íƒœ'ë¥¼ í•™ìŠµ

1. Prior Distributionì— ê¸°ë°˜í•˜ì—¬ í•˜ë‚˜ì˜ íƒìƒ‰ í•¨ìˆ˜ ê°€ì •
2. **Exploartion** : ë§¤ë²ˆ ìƒˆë¡œìš´ Samplingì„ ì‚¬ìš©í•´ ëª©ì í•¨ìˆ˜ë¥¼ Testí•  ì‹œ, í•´ë‹¹ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ëª©ì í•¨ìˆ˜ì˜ Prior Distributionì„ update
3. **Exploitation** : Posterior distributionì— ì˜í•´ ì–»ì€ global minimumì´ ë‚˜íƒ€ë‚  ê°€ëŠ¥ì„±ì´ ë†’ì€ ìœ„ì¹˜ì—ì„œ ì•Œê³ ë¦¬ì¦˜ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

### ì£¼ì˜í•  ì ğŸ¤¡

- ìµœì í•´ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì§€ì ì—ì„œ samplingì´ ê³„ì† ì¼ì–´ë‚  ìˆ˜ ìˆìŒ(exploitation) -> ì´ ì§€ì ì´ local minimumì´ë©´ ê±°ê¸°ì„œ ê³„ì† ë¨¸ë¬´ë¥´ê²Œ ë˜ëŠ” ê²ƒ
- ì´ ë•Œë¬¸ì— exploration ë° exploitation ì‚¬ì´ì— balance pointë¥¼ ì°¾ê²Œ ë¨

Source : https://velog.io/@crosstar1228/MLHyperparameter-tuning-%EA%B8%B0%EB%B2%95%EC%9D%98-3%EA%B0%80%EC%A7%80GridSearch-RandomSearch-Bayesian-Optimization
